{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation for brain tumor segmentation\n",
    "\n",
    "## Qimin Zhang and Weiwei Qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "import nibabel as nib\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "import skimage.transform\n",
    "import tqdm\n",
    "\n",
    "torch.manual_seed(4460)\n",
    "np.random.seed(4460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation Details\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9e5ed15becbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Computation Details'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\tDevice Used: ({device})  {torch.cuda.get_device_name(torch.cuda.current_device())}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Packages Used Versions:-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/BMEN4460/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/BMEN4460/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m             raise RuntimeError(\n\u001b[1;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/BMEN4460/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mFound\u001b[0m \u001b[0mno\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0mon\u001b[0m \u001b[0myour\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPlease\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mthat\u001b[0m \u001b[0myou\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0mhave\u001b[0m \u001b[0man\u001b[0m \u001b[0mNVIDIA\u001b[0m \u001b[0mGPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minstalled\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdriver\u001b[0m \u001b[0;32mfrom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m http://www.nvidia.com/Download/index.aspx\"\"\")\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# TODO: directly link to the alternative bin that needs install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: \nFound no NVIDIA driver on your system. Please check that you\nhave an NVIDIA GPU and installed a driver from\nhttp://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Computation Details')\n",
    "print(f'\\tDevice Used: ({device})  {torch.cuda.get_device_name(torch.cuda.current_device())}\\n')\n",
    "\n",
    "print('Packages Used Versions:-')\n",
    "print(f'\\tPytorch Version: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert .nii.gz files to numpy.\n",
    "Starts from dataPath and expects Task01_BrainTumour folder, containing imagesTr and labelsTr.\n",
    "Creates folders with numpy files.\n",
    "\"\"\"\n",
    "\n",
    "# Parser\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataPath', type=str, default='/rsrch1/ip/jrcalabrese')\n",
    "parser.add_argument('-r', type=bool, help='If True, it will downsample images.', default=True)\n",
    "parser.add_argument('-size', type=int, help=\"If -r is True, it will downsample to -size.\", default=32)\n",
    "parser.add_argument('-low', type=int, help=\"Lower slice bound.\", default=46)\n",
    "parser.add_argument('-high', type=int, help=\"Upper slice bound.\", default=110)\n",
    "parser.add_argument('-clip', type=bool, help=\"If True, it will clip labels to 0,1.\", default=True)\n",
    "parser.add_argument('-chanFirst', type=bool, help=\"If True, puts channel axis first.\", default=True)\n",
    "parser.add_argument('-cxlow', type=int, help=\"Crop lower bound on x-axis\", default=50)\n",
    "parser.add_argument('-cxhigh', type=int, help=\"Crop higher bound on x-axis\", default=195)\n",
    "parser.add_argument('-cylow', type=int, help=\"Crop lower bound on y-axis\", default=20)\n",
    "parser.add_argument('-cyhigh', type=int, help=\"Crop higher bound on y-axis\", default=200)\n",
    "args = parser.parse_args()\n",
    "\n",
    "dataPath = args.dataPath\n",
    "RESIZE = args.r\n",
    "SIZE = args.size\n",
    "SLICE_LOW = args.low\n",
    "SLICE_HIGH = args.high\n",
    "CLIP = args.clip\n",
    "CHANFIRST = args.chanFirst\n",
    "CROP_X_LOW = args.cxlow\n",
    "CROP_X_HIGH = args.cxhigh\n",
    "CROP_Y_LOW = args.cylow\n",
    "CROP_Y_HIGH = args.cyhigh\n",
    "\n",
    "print(f'dataPath is {dataPath}')\n",
    "\n",
    "# before we start, a helper function to resize images\n",
    "def img_resize(img,\n",
    "    lower=SLICE_LOW,\n",
    "    upper=SLICE_HIGH,\n",
    "    xlower=CROP_X_LOW,\n",
    "    xupper=CROP_X_HIGH,\n",
    "    ylower=CROP_Y_LOW,\n",
    "    yupper=CROP_Y_HIGH,\n",
    "    size=SIZE,\n",
    "    inp=True,\n",
    "    clip=False):\n",
    "    \"\"\"\n",
    "    img is a 3d or 4d numpy array: DxDxSxC\n",
    "        - D is dimension of width and height\n",
    "        - S is the number of slices\n",
    "        - C is the number of channels\n",
    "    0 <= lower < upper <= S\n",
    "    0 <= size <= D\n",
    "    \n",
    "    if clip = True, it groups all non-background together.\n",
    "    \"\"\"\n",
    "    if inp:\n",
    "        img = img[xlower:xupper,ylower:yupper,lower:upper,:]\n",
    "        slices = img.shape[2]\n",
    "        channels = img.shape[3]\n",
    "        img = skimage.transform.resize(img,(size,size,slices,channels))\n",
    "        return img\n",
    "    else:\n",
    "        img = img[xlower:xupper,ylower:yupper,lower:upper]\n",
    "        slices = img.shape[2]\n",
    "        img = skimage.transform.resize(img,\n",
    "                                      (size,size,slices),\n",
    "                                      preserve_range=True,\n",
    "                                      anti_aliasing=False,\n",
    "                                      order=0)\n",
    "        img = img.astype('uint8')\n",
    "        if clip:\n",
    "            img = np.clip(img,0,1)\n",
    "        return img\n",
    "\n",
    "\n",
    "# Here we go ---------------------\n",
    "# obtain paths to data and perform sanity check\n",
    "trainpath = os.path.join(dataPath, 'Task01_BrainTumour', 'imagesTr')\n",
    "labelspath = os.path.join(dataPath, 'Task01_BrainTumour', 'labelsTr')\n",
    "\n",
    "imgPaths = os.listdir(trainpath)\n",
    "trainlocations = []\n",
    "for path in imgPaths:\n",
    "    if path.endswith('.nii.gz'):\n",
    "        trainlocations.append(path)\n",
    "\n",
    "imgPaths = os.listdir(labelspath)\n",
    "labelslocations = []\n",
    "for path in imgPaths:\n",
    "    if path.endswith('.nii.gz'):\n",
    "        labelslocations.append(path)\n",
    "\n",
    "assert trainlocations == labelslocations\n",
    "\n",
    "# input data\n",
    "if RESIZE:\n",
    "    newPath = os.path.join(dataPath, 'numpyData'+str(SIZE))\n",
    "else:\n",
    "    newPath = os.path.join(dataPath, 'numpyDataOG')\n",
    "if not os.path.exists(newPath):\n",
    "    os.mkdir(newPath)\n",
    "\n",
    "numtrainpath = os.path.join(newPath, 'source')\n",
    "if os.path.exists(numtrainpath):\n",
    "    print('Folder already exists, so I did not create any numpy from train.')\n",
    "else:\n",
    "    os.mkdir(numtrainpath)\n",
    "\n",
    "    print('I am starting to convert training images.')\n",
    "    path = trainpath\n",
    "    trainprogress = tqdm.tqdm(enumerate(trainlocations))\n",
    "    for i, imageLocation in trainprogress:\n",
    "        trainprogress.set_description(f\"Processing image {imageLocation}\")\n",
    "        # get the .nii image\n",
    "        imageData = nib.load(os.path.join(path,imageLocation))\n",
    "        # convert to numpy\n",
    "        numpyImage = imageData.get_data()\n",
    "        if RESIZE:\n",
    "            numpyImage = img_resize(numpyImage)\n",
    "        if CHANFIRST:\n",
    "            numpyImage = np.transpose(numpyImage,(3,0,1,2))\n",
    "        np.save(os.path.join(numtrainpath, imageLocation), numpyImage)\n",
    "\n",
    "# output data\n",
    "numlabelspath = os.path.join(newPath, 'target')\n",
    "if os.path.exists(numlabelspath):\n",
    "    print('Folder alreay exists, so I did not create any numpy files from labels.')\n",
    "else:\n",
    "    os.mkdir(numlabelspath)\n",
    "\n",
    "    print('I am starting to convert labels images.')\n",
    "    path = labelspath\n",
    "    labelsprogress = tqdm.tqdm(enumerate(labelslocations))\n",
    "    for i, imageLocation in labelsprogress:\n",
    "        labelsprogress.set_description(f\"Processing image {imageLocation}\")\n",
    "        # get the .nii image\n",
    "        imageData = nib.load(os.path.join(path, imageLocation))\n",
    "        # convert to numpy\n",
    "        numpyImage = imageData.get_data()\n",
    "        # resize\n",
    "        if RESIZE:\n",
    "            numpyImage = img_resize(numpyImage,inp=False,clip=CLIP)\n",
    "        # save\n",
    "        np.save(os.path.join(numlabelspath,imageLocation), numpyImage)\n",
    "\n",
    "print('All done, I think.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load('./data/all_gbm_pre_reg/').getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 BMEN4460",
   "language": "python",
   "name": "bmen4460"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
